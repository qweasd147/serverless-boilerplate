## 주의사항

### 1. cold star & warm start

앞서 설명한대로 일정시간 함수가 실행되지 않으면 컨테이너가 종료된 상태로 유지된다. 그러면서 생긴 문제점은 이렇게 종료된 상태에서 함수 트리거가 발동되면 다시 컨테이너를 올리는것부터 시작된다. 이떄의 start를 `cold start`라고 한다. 반대로 주기적으로 실행되면서 컨테이너 시작부터가 아닌 그냥 함수를 바로 시행하는 start를 `warm start`라고 한다.

만약 `cold start`를 하게되면 당연히 시간이 오래걸리게 된다. 프로그램마다 다 다르겠지만 그래도 1~3초 정도 더 추가적으로 걸린다고 한다. 이러한 시간을 낭비하려면 어쩔수없이 주기적으로 함수를 실행시켜 컨테이너가 종료되는 것을 막는것 밖에 없다고 한다(`aws`에서도 따로 가이드가 없다고 함). health check api를 만들어 주기적으로 만들던가 `cloud watch`를 통해 이벤트 트리거를 주기적으로 발동 시키는게 그나마 최선이라고 한다. `2019 kakao developer` 세미나에서 자신들이 테스트해본 결과 300초 이하로 주기적으로 발동시키면 `warm start`가 발동 되지 않는다고 하고, 혹시 몰라서 60초정도로 주기적으로 함수를 발동시킨다고 하였다.

### 2. Concurrency

#### Reserved Concurrency

함수가 실행되는 동시 개수를 제한한다. 이는 계정 & 리전별로 제한이 있으니까, 중요한 함수와 널널한 함수를 나누어서 각각 따로 제한을 두는게 좋다. 말이 좋아 서버리스지 알면 알수록 성능 튜닝 요소 & 제한이 은근히 있다(물론 서버를 직접 구축하는것 보단 훨씬 적지만).

아무튼 `capacity`값을 셋팅하여 해당 리전의 함수를 동시 실행 개수를 제한해서 다른 함수 실행을 보장 할 수있다.

**2019년에 추가된 사항**

#### Provisioned Concurrency

`cold start`와 `Concurrency`문제를 해결하기 위해 `Provisioned Concurrency`가 나왔다(`Concurrency`는 해결이라기보다는 한곳에서 관리가 가능하다). lambda에 보면
셋팅이 직관적으로 나와있어서 쉽게 셋팅이 가능하고 해놓으면 항상 대기상태인 vm만들어 놓는다. 근데 이 셋팅을 하면 과금 정책이 `요청 & 처리 시간`이 아니라
ec2처럼 그냥 돈이 계속 나가기 때문에 좋은건지 모르겠다(이쯤 되면 ec2도 한번쯤 생각해봐야 한다고 생각) 물론 `auto scaling` 엄청 좋긴하지만

**TODO**
servlerless로 Provisioned Concurrency 핸들링

### 3. API Gateway를 통한 제한

트리거를 API Gateway를 통해 제한 할 수도 있다. cors를 제한해서 허용된 host만 처리한다던지, API를 발급 & import해서 인증된 request만 함수를 발동하도록 실행 제한이 가능하다.
사용계획도 한번에 셋팅하여 일별 or 월별 사용량도 제한할 수 있긴 하다.

### 4. 함수 실행시간

람다 실행당 최대 15분 까지만 실행된다. 오래된 문서나 `overflow` 보면 3분? 5분?이라고 나와있는데 늘어났다. 아무튼 그 이상 걸리는 작업은 다른 서비스(`aws batch`)등을 써야한다.

### 5. remove

`$ sls remove` 옵션을 사용하여 원격 배포된 `serverless` 내용을 없앨수 있다. 하지만 이는 매우매우 위험하다. 만약 db등의 리소스가 `serverless`에 등록되어 있다면 `remove`시에 함께 테이블 정보도 싹다 날라간다. 당연히 `cloud watch`에 쌓인 로그도 함께 날라간다. 따라서 이를 방지하려면 귀찮더라도 DB는 `serverless`에서 관리되는게 아닌 그냥 직접 관리해서 접근 하거나 그냥 함부로 삭제가 아닌 소스 업데이트만 사용해야 한다.
